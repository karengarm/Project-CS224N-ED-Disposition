{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d75d8979",
   "metadata": {},
   "source": [
    "# Predict ED_dispo with result from Lbl2TransformerVec and without"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "802e39c0",
   "metadata": {},
   "source": [
    "For architecture and weight initialization, we will compare:\n",
    "\n",
    "• <b> BERT (baseline) \n",
    "\n",
    "• BioBERT\n",
    "\n",
    "• Clinical BioBERT\n",
    "    \n",
    "• squeezebert-uncased\n",
    "\n",
    "• BlueBERT\n",
    "\n",
    "• XLNet (baseline)\n",
    "\n",
    "• Clinical XLnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ceaac702",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tensorflow_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "486d780c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tensorflow-text --no-dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8f0be11",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-12 14:35:43.130646: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-12 14:35:43.284861: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-03-12 14:35:43.898111: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/amazon/efa/lib64:/opt/amazon/openmpi/lib64:/usr/local/cuda/efa/lib:/usr/local/cuda/lib:/usr/local/cuda:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/targets/x86_64-linux/lib:/usr/local/lib:/usr/lib:/lib:\n",
      "2023-03-12 14:35:43.898241: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/amazon/efa/lib64:/opt/amazon/openmpi/lib64:/usr/local/cuda/efa/lib:/usr/local/cuda/lib:/usr/local/cuda:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/targets/x86_64-linux/lib:/usr/local/lib:/usr/lib:/lib:\n",
      "2023-03-12 14:35:43.898251: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "import os\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix, roc_curve, auc\n",
    "import re\n",
    "import tensorflow as tf\n",
    "from transformers import TFXLNetModel, XLNetTokenizer\n",
    "from transformers import AutoTokenizer, AutoModel, TFAutoModel, TFBertModel\n",
    "from sklearn.utils.fixes import loguniform\n",
    "from sklearn.model_selection import  train_test_split\n",
    "from sklearn.model_selection import ParameterSampler\n",
    "import tensorflow_hub as hub\n",
    "import json\n",
    "import csv \n",
    "\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import mlflow\n",
    "import mlflow.keras\n",
    "import tensorflow_text as text\n",
    "import seaborn as sns\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27fd0820",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install mlflow\n",
    "#!databricks configure --host https://community.cloud.databricks.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "404b4607",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found GPU at: /device:GPU:0\n",
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: Tesla T4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-12 14:35:45.507937: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-12 14:35:45.542761: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-12 14:35:45.544764: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-12 14:35:45.545613: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-12 14:35:47.548223: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-12 14:35:47.549216: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-12 14:35:47.550043: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-12 14:35:47.550809: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /device:GPU:0 with 177 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:1e.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "\n",
    "device_name = tf.test.gpu_device_name()\n",
    "\n",
    "if device_name == '/device:GPU:0':\n",
    "    print('Found GPU at: {}'.format(device_name))\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "print('We will use the GPU:', torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b4e22c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "torch.cuda.ipc_collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d107baee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-12 14:35:47.578025: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-12 14:35:47.578893: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-12 14:35:47.579655: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-12 14:35:47.580964: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-12 14:35:47.581805: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-12 14:35:47.582559: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-12 14:35:47.583362: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-12 14:35:47.584114: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-12 14:35:47.584839: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 177 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:1e.0, compute capability: 7.5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.eager.context._EagerDeviceContext at 0x7fc256b72cc0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "tf.debugging.set_log_device_placement(True)\n",
    "tf.device('/device:GPU:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec8278f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: DATABRICKS_USERNAME='karengar@stanford.edu'\n",
      "env: DATABRICKS_PASSWORD='Projectcs224*'\n"
     ]
    }
   ],
   "source": [
    "%env  DATABRICKS_USERNAME= 'karengar@stanford.edu' \n",
    "%env  DATABRICKS_PASSWORD = 'Projectcs224*'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4a2ed5",
   "metadata": {},
   "source": [
    " - Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7a32f01d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>CSN</th>\n",
       "      <th>Rads_order_ID</th>\n",
       "      <th>Study</th>\n",
       "      <th>Impression</th>\n",
       "      <th>ED_dispo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>80343</td>\n",
       "      <td>131318610796</td>\n",
       "      <td>755426017</td>\n",
       "      <td>XR ELBOW 3 VIEWS LEFT</td>\n",
       "      <td>1.  No displaced fracture or traumatic malalig...</td>\n",
       "      <td>Discharge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>66645</td>\n",
       "      <td>131314132694</td>\n",
       "      <td>741821327</td>\n",
       "      <td>XR CHEST 1 VIEW</td>\n",
       "      <td>1.  Apparent retrocardiac opacity favored to b...</td>\n",
       "      <td>Admit to Inpatient</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>76374</td>\n",
       "      <td>131317332223</td>\n",
       "      <td>751367975</td>\n",
       "      <td>XR CHEST 1 VIEW</td>\n",
       "      <td>1.  No acute cardiopulmonary disease.</td>\n",
       "      <td>Discharge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>66912</td>\n",
       "      <td>131314275465</td>\n",
       "      <td>742214156</td>\n",
       "      <td>XR CHEST 1 VIEW</td>\n",
       "      <td>1.  Interval improvement in aeration of the ri...</td>\n",
       "      <td>Admit to Inpatient</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>118086</td>\n",
       "      <td>131329544269</td>\n",
       "      <td>789721134</td>\n",
       "      <td>CT HEAD WO IV CONTRAST</td>\n",
       "      <td>1.  No acute intracranial abnormality. 2.  Sca...</td>\n",
       "      <td>Discharge</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0           CSN  Rads_order_ID                   Study  \\\n",
       "0       80343  131318610796      755426017   XR ELBOW 3 VIEWS LEFT   \n",
       "1       66645  131314132694      741821327         XR CHEST 1 VIEW   \n",
       "2       76374  131317332223      751367975         XR CHEST 1 VIEW   \n",
       "3       66912  131314275465      742214156         XR CHEST 1 VIEW   \n",
       "4      118086  131329544269      789721134  CT HEAD WO IV CONTRAST   \n",
       "\n",
       "                                          Impression            ED_dispo  \n",
       "0  1.  No displaced fracture or traumatic malalig...           Discharge  \n",
       "1  1.  Apparent retrocardiac opacity favored to b...  Admit to Inpatient  \n",
       "2              1.  No acute cardiopulmonary disease.           Discharge  \n",
       "3  1.  Interval improvement in aeration of the ri...  Admit to Inpatient  \n",
       "4  1.  No acute intracranial abnormality. 2.  Sca...           Discharge  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test = pd.read_csv('/root/data/ed_test.csv')\n",
    "data_train = pd.read_csv('/root/data/ed_train.csv')\n",
    "data_val = pd.read_csv('/root/data/ed_val.csv')\n",
    "data_val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1e28be02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#result_l2v = pd.read_csv('/root/Project-CS224N-ED-Disposition/result_l2v_v1.csv') \n",
    "#result_l2v.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7d74f81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_curve(y_proba, y_test, labels, mlflow, split_type):\n",
    "    # Plots the Probability Distributions and the ROC Curves One vs Rest\n",
    "    fig = plt.figure(figsize = (17, 8))\n",
    "    bins = [i/20 for i in range(20)] + [1]\n",
    "    roc_auc_ovr = {}\n",
    "    for i in range(len(labels)):\n",
    "        # Gets the class\n",
    "        c = labels[i]\n",
    "\n",
    "        # Prepares an auxiliar dataframe to help with the plots\n",
    "        df_aux = pd.DataFrame()\n",
    "        df_aux['class'] = [1 if y == c else 0 for y in y_test]\n",
    "        df_aux['prob'] = y_proba[:, i]\n",
    "        df_aux = df_aux.reset_index(drop = True)\n",
    "\n",
    "        # Plots the probability distribution for the class and the rest\n",
    "        fig_upper = plt.subplot(2, 4, i+1)\n",
    "        x = df_aux[df_aux['class'] ==0]\n",
    "        plt.hist(x['prob'], density=True, label='Rest')\n",
    "        y = df_aux[df_aux['class'] ==1]\n",
    "        plt.hist(y['prob'], density=True, label=f\" {c}\", bins = bins)\n",
    "        plt.title(c)\n",
    "        plt.legend(loc='upper right')\n",
    "        plt.xlabel(f\"P(x = {c})\")\n",
    "        #plt.show()\n",
    "        #mlflow.log_figure(fig, f\"Histogram: {c}.png\") \n",
    "\n",
    "\n",
    "        # Calculates the ROC Coordinates and plots the ROC Curves\n",
    "        fpr, tpr, thresholds = roc_curve(df_aux['class'], df_aux['prob'], pos_label=1)\n",
    "        mauc = auc(fpr, tpr)\n",
    "        fig_bottom = plt.subplot(2, 4, i+5)\n",
    "        plt.title( f\"ROC: {c}\")\n",
    "        plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % mauc)\n",
    "        plt.legend(loc = 'lower right')\n",
    "        plt.plot([0, 1], [0, 1],'r--')\n",
    "        plt.xlim([0, 1])\n",
    "        plt.ylim([0, 1])\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        #plt.show()\n",
    "        mlflow.log_metric(\"auc_\" + split_type + \"_\"+  c, mauc) \n",
    "\n",
    "    plt.tight_layout()\n",
    "    mlflow.log_figure(fig, \"Hist_and_ROC_\" + c+ \"_\"+ split_type + \".png\") \n",
    "    \n",
    "def evaluate(y_test, y_pred, mlflow,  split_type):\n",
    "    \"\"\"\n",
    "    Evaluation function. For each of the text in evaluation data, it reads the score from\n",
    "    the predictions made. And based on this, it calculates the values of\n",
    "    True positive, True negative, False positive, and False negative.\n",
    "\n",
    "    :param y_test: true labels\n",
    "    :param y_pred: predicted labels\n",
    "    :param labels: list of possible labels\n",
    "    :return: evaluation metrics for classification like, precision, recall, and f_score\n",
    "    \"\"\"\n",
    "     \n",
    "    b = np.zeros_like(y_pred)\n",
    "    b[np.arange(len(y_pred)), y_pred.argmax(1)] = 1\n",
    "    y_proba = y_pred\n",
    "\n",
    "    y_pred = pd.DataFrame(b, columns = list(y_test.columns))\n",
    "    y_pred = y_pred.idxmax(axis=1)\n",
    "    y_test = y_test.idxmax(axis=1)\n",
    "\n",
    "    labels = list(y_test.unique())\n",
    "    labels = sorted(labels)\n",
    "\n",
    "    plot_roc_curve(y_proba, y_test, labels, mlflow, split_type)\n",
    "\n",
    "    \n",
    "    confusion = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    # importing accuracy_score, precision_score, recall_score, f1_score\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average= None)\n",
    "    recall = recall_score(y_test, y_pred, average= None)\n",
    "    f1score = f1_score(y_test, y_pred, average= None)\n",
    "\n",
    "\n",
    "    report = classification_report(y_test, y_pred, target_names = labels)\n",
    "    print(report)\n",
    "    f_name = 'report_ '+ split_type +'.yaml'\n",
    "    mlflow.log_dict(report, f_name)\n",
    "    #mlflow.log_metric(\"auc_\" + split_type, mauc) \n",
    "    mlflow.log_metric(\"accuracy_\"+ split_type, accuracy)\n",
    "   \n",
    "\n",
    "    return accuracy, precision, recall, f1score\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def mlflow_log_parameters(parameter):\n",
    "    # Log parameters\n",
    "    mlflow.log_param(\"dropout\", parameter['dropout'])\n",
    "    mlflow.log_param(\"learning_rate\", parameter['learning_rate'])\n",
    "    mlflow.log_param(\"epochs\", parameter['epochs'])\n",
    "    mlflow.log_param(\"batch_size\", parameter['batch_size'])\n",
    "\n",
    "\n",
    "\n",
    "def get_inputs_biobert(sentences):\n",
    "    def mean_pooling(model_output, attention_mask):\n",
    "        token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n",
    "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "        return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "\n",
    "    # Load model from HuggingFace Hub\n",
    "    tokenizer = AutoTokenizer.from_pretrained('pritamdeka/BioBERT-mnli-snli-scinli-scitail-mednli-stsb')\n",
    "    model = AutoModel.from_pretrained('pritamdeka/BioBERT-mnli-snli-scinli-scitail-mednli-stsb')\n",
    "\n",
    "    # Tokenize sentences\n",
    "    encoded_input = tokenizer(sentences, padding=True, truncation=True, return_tensors='pt')\n",
    "\n",
    "    # Compute token embeddings\n",
    "    with torch.no_grad():\n",
    "        model_output = model(**encoded_input)\n",
    "\n",
    "    # Perform pooling. In this case, mean pooling.\n",
    "    sentence_embeddings = mean_pooling(model_output, encoded_input['attention_mask'])\n",
    "    return sentence_embeddings\n",
    "\n",
    "def create_bert(bert, learning_rate=1e-3, dropout=0.1):\n",
    "    input_ids = tf.keras.layers.Input(shape=(158,), dtype=tf.int32, name=\"input_ids\")\n",
    "    input_mask = tf.keras.layers.Input(shape=(158,), dtype=tf.int32, name=\"attention_mask\")\n",
    "\n",
    "    embeddings = bert(input_ids, attention_mask = input_mask)[0]\n",
    "    bert.trainable = False\n",
    "    out = tf.keras.layers.GlobalMaxPool1D()(embeddings)\n",
    "    y = tf.keras.layers.Dense(4, activation='softmax', name='outputs')(out)\n",
    "\n",
    "    # Compile model\n",
    "    model = tf.keras.Model(inputs=[input_ids, input_mask], outputs=y)\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate), loss='categorical_crossentropy', \n",
    "               metrics=[tf.keras.metrics.AUC(), 'accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def training_test_mae( mlflow, history):\n",
    "    # Plot training and test loss at each epoch \n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(history.history['accuracy'], label='Training acc')\n",
    "    #plt.plot(history.history['val_accuracy'], label='Validation acc')\n",
    "    plt.title('Training and validation accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    mlflow.log_figure(fig, \"training_validation_accuracy.png\") \n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    plt.plot(history.history['loss'])\n",
    "    #plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    #plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()\n",
    "    mlflow.log_figure(fig, \"training_validation_loss.png\") \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d50d8eb",
   "metadata": {},
   "source": [
    "# Scenario 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e31fac1",
   "metadata": {},
   "source": [
    "- Without using results from l2v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "368484dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='dbfs:/databricks/mlflow-tracking/1072956514573773', creation_time=1678354854333, experiment_id='1072956514573773', last_update_time=1678578685444, lifecycle_stage='active', name='/Users/karengar@stanford.edu/BERT_l2v', tags={'mlflow.experiment.sourceName': '/Users/karengar@stanford.edu/BERT_l2v',\n",
       " 'mlflow.experimentType': 'MLFLOW_EXPERIMENT',\n",
       " 'mlflow.ownerEmail': 'karengar@stanford.edu',\n",
       " 'mlflow.ownerId': '3913783827154434'}>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_tracking_uri(\"databricks\")\n",
    "mlflow.set_experiment(\"/Users/karengar@stanford.edu/BERT_l2v\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "30bdc03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data[list(result_l2v.iloc[:, 3:].columns)] = result_l2v.iloc[:, 3:]\n",
    "#data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ab2e4643",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = data_train.drop(['Unnamed: 0', 'ED_dispo', 'CSN', 'Rads_order_ID'], axis=1)\n",
    "X_test =  data_test.drop(['Unnamed: 0', 'ED_dispo', 'CSN', 'Rads_order_ID'], axis=1)\n",
    "X_val = data_val.drop(['Unnamed: 0', 'ED_dispo', 'CSN', 'Rads_order_ID'], axis=1)\n",
    "\n",
    "# Assigning numerical values and storing in another column\n",
    "y_train =  pd.get_dummies(data_train['ED_dispo'])\n",
    "y_test = pd.get_dummies(data_test['ED_dispo'])[list(y_train.columns)]\n",
    "y_val =  pd.get_dummies(data_val['ED_dispo'])[list(y_train.columns)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f453718b",
   "metadata": {},
   "outputs": [],
   "source": [
    "del data_train, data_test, data_val "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1c5075ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(0)\n",
    "param_dist = {    'dropout': [0.1,0.2, 0.3],\n",
    "                  'learning_rate': loguniform.rvs(1e-3, 1e-1, size= 10),\n",
    "                  'epochs': [1],#[5, 10],\n",
    "                  'batch_size':[64, 128]\n",
    "                  }\n",
    "            \n",
    "dict_parameters = ParameterSampler(param_distributions=param_dist, n_iter= 10, random_state=rng)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8934fff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-12 14:35:48.678570: I tensorflow/core/common_runtime/placer.cc:114] input: (_Arg): /job:localhost/replica:0/task:0/device:GPU:0\n",
      "2023-03-12 14:35:48.678605: I tensorflow/core/common_runtime/placer.cc:114] _EagerConst: (_EagerConst): /job:localhost/replica:0/task:0/device:GPU:0\n",
      "2023-03-12 14:35:48.678623: I tensorflow/core/common_runtime/placer.cc:114] output_RetVal: (_Retval): /job:localhost/replica:0/task:0/device:GPU:0\n",
      "2023-03-12 14:35:48.683844: I tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:735] failed to allocate 177.00M (185597952 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2023-03-12 14:35:48.688483: I tensorflow/core/common_runtime/placer.cc:114] resource_RetVal: (_Retval): /job:localhost/replica:0/task:0/device:GPU:0\n",
      "2023-03-12 14:35:48.688509: I tensorflow/core/common_runtime/placer.cc:114] VarHandleOp: (VarHandleOp): /job:localhost/replica:0/task:0/device:GPU:0\n",
      "2023-03-12 14:35:48.690270: I tensorflow/core/common_runtime/placer.cc:114] resource: (_Arg): /job:localhost/replica:0/task:0/device:GPU:0\n",
      "2023-03-12 14:35:48.690295: I tensorflow/core/common_runtime/placer.cc:114] value: (_Arg): /job:localhost/replica:0/task:0/device:GPU:0\n",
      "2023-03-12 14:35:48.690307: I tensorflow/core/common_runtime/placer.cc:114] AssignVariableOp: (AssignVariableOp): /job:localhost/replica:0/task:0/device:GPU:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Shape in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Fill in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Fill in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op StatelessRandomGetKeyCounter in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op StatelessTruncatedNormalV2 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Mul in device /job:localhost/replica:0/task:0/device:GPU:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-12 14:35:48.971663: I tensorflow/core/common_runtime/placer.cc:114] input: (_Arg): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "2023-03-12 14:35:48.971709: I tensorflow/core/common_runtime/placer.cc:114] _EagerConst: (_EagerConst): /job:localhost/replica:0/task:0/device:GPU:0\n",
      "2023-03-12 14:35:48.971720: I tensorflow/core/common_runtime/placer.cc:114] output_RetVal: (_Retval): /job:localhost/replica:0/task:0/device:GPU:0\n",
      "2023-03-12 14:35:48.980487: I tensorflow/core/common_runtime/placer.cc:114] input: (_Arg): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "2023-03-12 14:35:48.980525: I tensorflow/core/common_runtime/placer.cc:114] Shape: (Shape): /job:localhost/replica:0/task:0/device:GPU:0\n",
      "2023-03-12 14:35:48.980535: I tensorflow/core/common_runtime/placer.cc:114] output_RetVal: (_Retval): /job:localhost/replica:0/task:0/device:GPU:0\n",
      "2023-03-12 14:35:48.984378: I tensorflow/core/common_runtime/placer.cc:114] dims: (_Arg): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "2023-03-12 14:35:48.984409: I tensorflow/core/common_runtime/placer.cc:114] value: (_Arg): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "2023-03-12 14:35:48.984419: I tensorflow/core/common_runtime/placer.cc:114] Fill: (Fill): /job:localhost/replica:0/task:0/device:GPU:0\n",
      "2023-03-12 14:35:48.984424: I tensorflow/core/common_runtime/placer.cc:114] output_RetVal: (_Retval): /job:localhost/replica:0/task:0/device:GPU:0\n",
      "2023-03-12 14:35:48.989947: I tensorflow/core/common_runtime/placer.cc:114] input: (_Arg): /job:localhost/replica:0/task:0/device:GPU:0\n",
      "2023-03-12 14:35:48.989980: I tensorflow/core/common_runtime/placer.cc:114] _EagerConst: (_EagerConst): /job:localhost/replica:0/task:0/device:GPU:0\n",
      "2023-03-12 14:35:48.989987: I tensorflow/core/common_runtime/placer.cc:114] output_RetVal: (_Retval): /job:localhost/replica:0/task:0/device:GPU:0\n",
      "2023-03-12 14:35:48.993382: I tensorflow/core/common_runtime/placer.cc:114] seed: (_Arg): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "2023-03-12 14:35:48.993419: I tensorflow/core/common_runtime/placer.cc:114] StatelessRandomGetKeyCounter: (StatelessRandomGetKeyCounter): /job:localhost/replica:0/task:0/device:GPU:0\n",
      "2023-03-12 14:35:48.993431: I tensorflow/core/common_runtime/placer.cc:114] key_RetVal: (_Retval): /job:localhost/replica:0/task:0/device:GPU:0\n",
      "2023-03-12 14:35:48.993440: I tensorflow/core/common_runtime/placer.cc:114] counter_RetVal: (_Retval): /job:localhost/replica:0/task:0/device:GPU:0\n",
      "2023-03-12 14:35:48.998425: I tensorflow/core/common_runtime/placer.cc:114] shape: (_DeviceArg): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "2023-03-12 14:35:48.998465: I tensorflow/core/common_runtime/placer.cc:114] key: (_Arg): /job:localhost/replica:0/task:0/device:GPU:0\n",
      "2023-03-12 14:35:48.998476: I tensorflow/core/common_runtime/placer.cc:114] counter: (_Arg): /job:localhost/replica:0/task:0/device:GPU:0\n",
      "2023-03-12 14:35:48.998485: I tensorflow/core/common_runtime/placer.cc:114] alg: (_DeviceArg): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "2023-03-12 14:35:48.998498: I tensorflow/core/common_runtime/placer.cc:114] StatelessTruncatedNormalV2: (StatelessTruncatedNormalV2): /job:localhost/replica:0/task:0/device:GPU:0\n",
      "2023-03-12 14:35:48.998506: I tensorflow/core/common_runtime/placer.cc:114] output_RetVal: (_Retval): /job:localhost/replica:0/task:0/device:GPU:0\n",
      "2023-03-12 14:35:49.003978: I tensorflow/core/common_runtime/placer.cc:114] x: (_Arg): /job:localhost/replica:0/task:0/device:GPU:0\n",
      "2023-03-12 14:35:49.004004: I tensorflow/core/common_runtime/placer.cc:114] y: (_Arg): /job:localhost/replica:0/task:0/device:GPU:0\n",
      "2023-03-12 14:35:49.004013: I tensorflow/core/common_runtime/placer.cc:114] Mul: (Mul): /job:localhost/replica:0/task:0/device:GPU:0\n",
      "2023-03-12 14:35:49.004019: I tensorflow/core/common_runtime/placer.cc:114] z_RetVal: (_Retval): /job:localhost/replica:0/task:0/device:GPU:0\n",
      "2023-03-12 14:35:59.005425: W tensorflow/tsl/framework/bfc_allocator.cc:479] Allocator (GPU_0_bfc) ran out of memory trying to allocate 84.95MiB (rounded to 89075712)requested by op Mul\n",
      "If the cause is memory fragmentation maybe the environment variable 'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation. \n",
      "Current allocation summary follows.\n",
      "Current allocation summary follows.\n",
      "2023-03-12 14:35:59.005456: I tensorflow/tsl/framework/bfc_allocator.cc:1034] BFCAllocator dump for GPU_0_bfc\n",
      "2023-03-12 14:35:59.005466: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (256): \tTotal Chunks: 5, Chunks in use: 5. 1.2KiB allocated for chunks. 1.2KiB in use in bin. 40B client-requested in use in bin.\n",
      "2023-03-12 14:35:59.005473: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (512): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-03-12 14:35:59.005480: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (1024): \tTotal Chunks: 1, Chunks in use: 1. 1.2KiB allocated for chunks. 1.2KiB in use in bin. 1.0KiB client-requested in use in bin.\n",
      "2023-03-12 14:35:59.005486: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (2048): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-03-12 14:35:59.005491: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (4096): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-03-12 14:35:59.005497: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (8192): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-03-12 14:35:59.005502: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (16384): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-03-12 14:35:59.005507: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (32768): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-03-12 14:35:59.005513: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (65536): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-03-12 14:35:59.005518: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (131072): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-03-12 14:35:59.005523: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (262144): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-03-12 14:35:59.005529: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (524288): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-03-12 14:35:59.005534: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (1048576): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-03-12 14:35:59.005539: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (2097152): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-03-12 14:35:59.005545: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (4194304): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-03-12 14:35:59.005553: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (8388608): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-03-12 14:35:59.005561: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (16777216): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-03-12 14:35:59.005569: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (33554432): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-03-12 14:35:59.005576: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (67108864): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-03-12 14:35:59.005584: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (134217728): \tTotal Chunks: 1, Chunks in use: 1. 159.30MiB allocated for chunks. 159.30MiB in use in bin. 84.95MiB client-requested in use in bin.\n",
      "2023-03-12 14:35:59.005593: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (268435456): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-03-12 14:35:59.005599: I tensorflow/tsl/framework/bfc_allocator.cc:1057] Bin for 84.95MiB was 64.00MiB, Chunk State: \n",
      "2023-03-12 14:35:59.005604: I tensorflow/tsl/framework/bfc_allocator.cc:1070] Next region of size 167038208\n",
      "2023-03-12 14:35:59.005614: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fc1a6000000 of size 256 next 1\n",
      "2023-03-12 14:35:59.005619: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fc1a6000100 of size 1280 next 2\n",
      "2023-03-12 14:35:59.005624: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fc1a6000600 of size 256 next 3\n",
      "2023-03-12 14:35:59.005628: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fc1a6000700 of size 256 next 4\n",
      "2023-03-12 14:35:59.005641: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fc1a6000800 of size 256 next 5\n",
      "2023-03-12 14:35:59.005645: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fc1a6000900 of size 256 next 6\n",
      "2023-03-12 14:35:59.005650: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fc1a6000a00 of size 167035648 next 18446744073709551615\n",
      "2023-03-12 14:35:59.005655: I tensorflow/tsl/framework/bfc_allocator.cc:1095]      Summary of in-use Chunks by size: \n",
      "2023-03-12 14:35:59.005661: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 5 Chunks of size 256 totalling 1.2KiB\n",
      "2023-03-12 14:35:59.005665: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 1280 totalling 1.2KiB\n",
      "2023-03-12 14:35:59.005671: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 167035648 totalling 159.30MiB\n",
      "2023-03-12 14:35:59.005676: I tensorflow/tsl/framework/bfc_allocator.cc:1102] Sum Total of in-use chunks: 159.30MiB\n",
      "2023-03-12 14:35:59.005680: I tensorflow/tsl/framework/bfc_allocator.cc:1104] total_region_allocated_bytes_: 167038208 memory_limit_: 185597952 available bytes: 18559744 curr_region_allocation_bytes_: 371195904\n",
      "2023-03-12 14:35:59.005688: I tensorflow/tsl/framework/bfc_allocator.cc:1110] Stats: \n",
      "Limit:                       185597952\n",
      "InUse:                       167038208\n",
      "MaxInUse:                    167038208\n",
      "NumAllocs:                           7\n",
      "MaxAllocSize:                167035648\n",
      "Reserved:                            0\n",
      "PeakReserved:                        0\n",
      "LargestFreeBlock:                    0\n",
      "\n",
      "2023-03-12 14:35:59.005695: W tensorflow/tsl/framework/bfc_allocator.cc:492] ******************************************************xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\n",
      "2023-03-12 14:35:59.005723: W tensorflow/core/framework/op_kernel.cc:1818] RESOURCE_EXHAUSTED: failed to allocate memory\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "Exception encountered when calling layer 'bert' (type TFBertMainLayer).\n\n{{function_node __wrapped__Mul_device_/job:localhost/replica:0/task:0/device:GPU:0}} failed to allocate memory [Op:Mul]\n\nCall arguments received by layer 'bert' (type TFBertMainLayer):\n  • input_ids=tf.Tensor(shape=(3, 5), dtype=int32)\n  • attention_mask=None\n  • token_type_ids=None\n  • position_ids=None\n  • head_mask=None\n  • inputs_embeds=None\n  • encoder_hidden_states=None\n  • encoder_attention_mask=None\n  • past_key_values=None\n  • use_cache=True\n  • output_attentions=False\n  • output_hidden_states=False\n  • return_dict=True\n  • training=False",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbert-base-cased\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m bert \u001b[38;5;241m=\u001b[39m \u001b[43mTFAutoModel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbert-base-cased\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/l2v/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:464\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    463\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m _get_model_class(config, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping)\n\u001b[0;32m--> 464\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    465\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    466\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    467\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    468\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    469\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    470\u001b[0m )\n",
      "File \u001b[0;32m/opt/conda/envs/l2v/lib/python3.10/site-packages/transformers/modeling_tf_utils.py:2753\u001b[0m, in \u001b[0;36mTFPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   2751\u001b[0m         model(model\u001b[38;5;241m.\u001b[39mdummy_inputs)  \u001b[38;5;66;03m# build the network with dummy inputs\u001b[39;00m\n\u001b[1;32m   2752\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2753\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdummy_inputs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# build the network with dummy inputs\u001b[39;00m\n\u001b[1;32m   2755\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m safetensors_from_pt:\n\u001b[1;32m   2756\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodeling_tf_pytorch_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_pytorch_state_dict_in_tf2_model\n",
      "File \u001b[0;32m/opt/conda/envs/l2v/lib/python3.10/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/opt/conda/envs/l2v/lib/python3.10/site-packages/transformers/modeling_tf_utils.py:433\u001b[0m, in \u001b[0;36munpack_inputs.<locals>.run_call_with_unpacked_inputs\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    430\u001b[0m     config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\n\u001b[1;32m    432\u001b[0m unpacked_inputs \u001b[38;5;241m=\u001b[39m input_processing(func, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfn_args_and_kwargs)\n\u001b[0;32m--> 433\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43munpacked_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/l2v/lib/python3.10/site-packages/transformers/models/bert/modeling_tf_bert.py:1115\u001b[0m, in \u001b[0;36mTFBertModel.call\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict, training)\u001b[0m\n\u001b[1;32m   1071\u001b[0m \u001b[38;5;129m@unpack_inputs\u001b[39m\n\u001b[1;32m   1072\u001b[0m \u001b[38;5;129m@add_start_docstrings_to_model_forward\u001b[39m(BERT_INPUTS_DOCSTRING\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch_size, sequence_length\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m   1073\u001b[0m \u001b[38;5;129m@add_code_sample_docstrings\u001b[39m(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1093\u001b[0m     training: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   1094\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[TFBaseModelOutputWithPoolingAndCrossAttentions, Tuple[tf\u001b[38;5;241m.\u001b[39mTensor]]:\n\u001b[1;32m   1095\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1096\u001b[0m \u001b[38;5;124;03m    encoder_hidden_states  (`tf.Tensor` of shape `(batch_size, sequence_length, hidden_size)`, *optional*):\u001b[39;00m\n\u001b[1;32m   1097\u001b[0m \u001b[38;5;124;03m        Sequence of hidden-states at the output of the last layer of the encoder. Used in the cross-attention if\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1113\u001b[0m \u001b[38;5;124;03m        `past_key_values`). Set to `False` during training, `True` during generation\u001b[39;00m\n\u001b[1;32m   1114\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1115\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1116\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1117\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1118\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1119\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1120\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1121\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1122\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1123\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1124\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1125\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1126\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1127\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1128\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1129\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1130\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m/opt/conda/envs/l2v/lib/python3.10/site-packages/transformers/modeling_tf_utils.py:433\u001b[0m, in \u001b[0;36munpack_inputs.<locals>.run_call_with_unpacked_inputs\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    430\u001b[0m     config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\n\u001b[1;32m    432\u001b[0m unpacked_inputs \u001b[38;5;241m=\u001b[39m input_processing(func, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfn_args_and_kwargs)\n\u001b[0;32m--> 433\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43munpacked_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/l2v/lib/python3.10/site-packages/transformers/models/bert/modeling_tf_bert.py:789\u001b[0m, in \u001b[0;36mTFBertMainLayer.call\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict, training)\u001b[0m\n\u001b[1;32m    786\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m token_type_ids \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    787\u001b[0m     token_type_ids \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mfill(dims\u001b[38;5;241m=\u001b[39minput_shape, value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m--> 789\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membeddings\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[38;5;66;03m# We create a 3D attention mask from a 2D tensor mask.\u001b[39;00m\n\u001b[1;32m    799\u001b[0m \u001b[38;5;66;03m# Sizes are [batch_size, 1, 1, to_seq_length]\u001b[39;00m\n\u001b[1;32m    800\u001b[0m \u001b[38;5;66;03m# So we can broadcast to [batch_size, num_heads, from_seq_length, to_seq_length]\u001b[39;00m\n\u001b[1;32m    801\u001b[0m \u001b[38;5;66;03m# this attention mask is more simple than the triangular masking of causal attention\u001b[39;00m\n\u001b[1;32m    802\u001b[0m \u001b[38;5;66;03m# used in OpenAI GPT, we just need to prepare the broadcast dimension here.\u001b[39;00m\n\u001b[1;32m    803\u001b[0m attention_mask_shape \u001b[38;5;241m=\u001b[39m shape_list(attention_mask)\n",
      "File \u001b[0;32m/opt/conda/envs/l2v/lib/python3.10/site-packages/transformers/models/bert/modeling_tf_bert.py:160\u001b[0m, in \u001b[0;36mTFBertEmbeddings.build\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbuild\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_shape: tf\u001b[38;5;241m.\u001b[39mTensorShape):\n\u001b[1;32m    159\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mname_scope(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mword_embeddings\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 160\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_weight\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m            \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mweight\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[43m            \u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvocab_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhidden_size\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[43m            \u001b[49m\u001b[43minitializer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mget_initializer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minitializer_range\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mname_scope(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_type_embeddings\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    167\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtoken_type_embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_weight(\n\u001b[1;32m    168\u001b[0m             name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124membeddings\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    169\u001b[0m             shape\u001b[38;5;241m=\u001b[39m[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mtype_vocab_size, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_size],\n\u001b[1;32m    170\u001b[0m             initializer\u001b[38;5;241m=\u001b[39mget_initializer(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minitializer_range),\n\u001b[1;32m    171\u001b[0m         )\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: Exception encountered when calling layer 'bert' (type TFBertMainLayer).\n\n{{function_node __wrapped__Mul_device_/job:localhost/replica:0/task:0/device:GPU:0}} failed to allocate memory [Op:Mul]\n\nCall arguments received by layer 'bert' (type TFBertMainLayer):\n  • input_ids=tf.Tensor(shape=(3, 5), dtype=int32)\n  • attention_mask=None\n  • token_type_ids=None\n  • position_ids=None\n  • head_mask=None\n  • inputs_embeds=None\n  • encoder_hidden_states=None\n  • encoder_attention_mask=None\n  • past_key_values=None\n  • use_cache=True\n  • output_attentions=False\n  • output_hidden_states=False\n  • return_dict=True\n  • training=False"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-cased')\n",
    "bert = TFAutoModel.from_pretrained(\"bert-base-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85e85aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = tokenizer(\n",
    "    text=X_train['Impression'].tolist(),\n",
    "    add_special_tokens=True,\n",
    "    max_length=158,\n",
    "    truncation=True,\n",
    "    padding=True,\n",
    "    return_tensors='tf',\n",
    "    return_token_type_ids=False,\n",
    "    return_attention_mask=True,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "X_test = tokenizer(\n",
    "    text=X_test['Impression'].tolist(),\n",
    "    add_special_tokens=True,\n",
    "    max_length=158,\n",
    "    truncation=True,\n",
    "    padding=True,\n",
    "    return_tensors='tf',\n",
    "    return_token_type_ids=False,\n",
    "    return_attention_mask=True,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "X_val = tokenizer(\n",
    "    text=X_val['Impression'].tolist(),\n",
    "    add_special_tokens=True,\n",
    "    max_length=158,\n",
    "    truncation=True,\n",
    "    padding=True,\n",
    "    return_tensors='tf',\n",
    "    return_token_type_ids=False,\n",
    "    return_attention_mask=True,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db44de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for parameter in dict_parameters:\n",
    "    print(parameter)\n",
    "    print('Training')\n",
    "    with mlflow.start_run(): \n",
    "        mlflow_log_parameters(parameter) \n",
    "        bert_model = create_bert(bert, parameter['learning_rate'], parameter['dropout'])\n",
    "        hist = bert_model.fit( x = {'input_ids':X_train['input_ids'], 'attention_mask':X_train['attention_mask']}, \n",
    "                     y=y_train, epochs=parameter['epochs'], batch_size=parameter['batch_size'])\n",
    "    \n",
    "        training_test_mae( mlflow, hist)\n",
    "        \n",
    "        print('Testing')\n",
    "        split_type = 'test'\n",
    "        y_pred = bert_model.predict(x = {'input_ids':X_test['input_ids'], 'attention_mask':X_test['attention_mask']})\n",
    "        accuracy, precision, recall, f1score = evaluate(y_test, y_pred, mlflow, split_type)\n",
    "        \n",
    "        print('Validation')\n",
    "        split_type = 'validation'\n",
    "        y_pred = bert_model.predict(x = {'input_ids':X_val['input_ids'], 'attention_mask':X_val['attention_mask']})\n",
    "        accuracy, precision, recall, f1score = evaluate(y_val, y_pred, mlflow,  split_type)\n",
    "        \n",
    "        mlflow.end_run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
